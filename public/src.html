<!-- public/src.html -->
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>SRC Client</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0"> <!-- For better mobile scaling -->
  <style>
    body {
      background-color: #121212;
      color: #e0e0e0;
      font-family: 'Courier New', Courier, monospace;
      font-size: 1.2em; /* Larger base font size */
      margin: 20px;
      display: flex;
      flex-direction: column;
      align-items: center; /* Center content */
      text-align: center;
    }
    h1 {
      color: #ffffff;
      border-bottom: 1px solid #444;
      padding-bottom: 5px;
      margin-bottom: 20px;
    }
    button {
      background-color: #333;
      color: #e0e0e0;
      border: 1px solid #555;
      padding: 12px 18px; /* Larger padding for buttons */
      margin: 10px 5px; /* More margin for buttons */
      cursor: pointer;
      border-radius: 4px;
      font-size: 1em; /* Relative to body font size */
    }
    button:hover {
      background-color: #444;
    }
    #status {
      font-weight: bold;
      margin-bottom: 15px;
    }
    #noteIndicator {
      background-color: #1f1f1f;
      border: 1px solid #333;
      border-radius: 5px;
      padding: 15px;
      margin-top: 20px;
      width: 80%; /* Adjust width as needed */
      max-width: 400px; /* Max width for larger screens */
    }
    #noteIndicator h3 {
        margin-top: 0;
        color: #ffffff;
    }
    #noteIndicator p {
        margin: 8px 0;
        font-size: 0.9em; /* Slightly smaller than body, but still larger overall */
    }
  </style>
</head>
<body>
  <h1>SRC Client</h1>
  <p id="status">Connecting...</p>
  <button id="startSessionButton" style="display: block;">Start Session</button>
  <button id="testTone" style="display: none;">Test Tone</button>
  <div id="noteIndicator">
    <h3>Last Note Received:</h3>
    <p id="lastNote">None</p>
    <p id="noteCount">Notes received: 0</p>
    <p id="audioStatus">Audio: Not initialized</p>
    <p id="audioState">State: Unknown</p>
    <p id="browserInfo">Browser: Checking...</p>
    <p id="volumeInfo">Volume: Unknown</p>
  </div>

  <script>
    const id = 'src-' + Math.random().toString(36).substr(2, 5);
    const ws = new WebSocket(`ws://${location.host}`);
    let audioContext;
    let audioInitialized = false;
    let noteCount = 0;

    // Drone specific nodes
    let droneOscillator = null;
    let droneGainNode = null;
    let dryGainDrone = null; // Separate dry gain for the drone
    let droneActive = false;

    // LFO specific nodes and parameters
    let lfo = null;
    let lfoGain = null;
    let currentLfoRate = 2; // Default LFO rate in Hz
    let currentLfoDepth = 0.5; // Default LFO depth (0 to 1)
    let currentLfoType = 'sine'; // Default LFO waveform

    // Delay effect nodes and parameters
    let delayNode = null;
    let feedbackNode = null;
    let wetGainNode = null; // To control overall level of delayed sound
    let currentDelayTime = 0;
    let currentFeedbackAmount = 0;
    const MAX_DELAY = 2.0; // Maximum delay time in seconds

    // Check browser support and capabilities
    function checkBrowserSupport() {
      const isIOS = /iPad|iPhone|iPod/.test(navigator.userAgent);
      const isAndroid = /Android/.test(navigator.userAgent);
      const isChrome = /Chrome/.test(navigator.userAgent);
      const isSafari = /Safari/.test(navigator.userAgent) && !isChrome;
      
      let browserInfo = `${isIOS ? 'iOS' : isAndroid ? 'Android' : 'Desktop'}`;
      if (isChrome) browserInfo += ' Chrome';
      else if (isSafari) browserInfo += ' Safari';
      
      document.getElementById('browserInfo').textContent = `Browser: ${browserInfo}`;
      
      // Check if Web Audio API is supported
      if (!window.AudioContext && !window.webkitAudioContext) {
        document.getElementById('audioStatus').textContent = 'Audio: Not supported';
        return false;
      }
      return true;
    }

    // Show init audio button initially
    document.getElementById('startSessionButton').style.display = 'block';
    document.getElementById('startSessionButton').onclick = startSession; 
    document.getElementById('testTone').onclick = () => playNote('A4');
    
    checkBrowserSupport();

    function updateAudioStatus(status) {
      document.getElementById('audioStatus').textContent = `Audio: ${status}`;
    }

    function updateAudioState() {
      if (audioContext) {
        document.getElementById('audioState').textContent = `State: ${audioContext.state}`;
      }
    }

    function updateNoteReceived(note) {
      noteCount++;
      document.getElementById('lastNote').textContent = note;
      document.getElementById('noteCount').textContent = `Notes received: ${noteCount}`;
      
      // Flash the indicator
      const indicator = document.getElementById('noteIndicator');
      indicator.style.backgroundColor = '#90EE90';
      setTimeout(() => {
        indicator.style.backgroundColor = '';
      }, 500);
    }

    async function startSession() {
        console.log('startSession: Initiating session...');
        await initAudio();

        if (audioInitialized) {
            console.log('startSession: Audio initialized.');
            document.getElementById('startSessionButton').style.display = 'none';
            document.getElementById('testTone').style.display = 'block';
        } else {
            console.error('startSession: Audio initialization failed.');
        }
    }

    async function initAudio() {
      console.log('initAudio: Attempting to initialize AudioContext...');
      try {
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        
        if (audioContext.state === 'suspended') {
          console.log('initAudio: AudioContext is suspended, attempting to resume...');
          await audioContext.resume();
        }
        
        // Initialize Delay Nodes
        delayNode = audioContext.createDelay(MAX_DELAY);
        feedbackNode = audioContext.createGain();
        wetGainNode = audioContext.createGain();

        // Set initial delay parameters (can be overridden by server)
        // These should be the global currentDelayTime and currentFeedbackAmount
        // which might have been set by a message before initAudio if ORC sends effect early.
        delayNode.delayTime.setValueAtTime(currentDelayTime, audioContext.currentTime);
        feedbackNode.gain.setValueAtTime(currentFeedbackAmount, audioContext.currentTime);
        wetGainNode.gain.setValueAtTime(1.0, audioContext.currentTime); // Start with wet signal at full volume

        console.log('initAudio: Delay nodes initialized.');

        // Create the separate dry gain for the drone here, so it's ready
        dryGainDrone = audioContext.createGain();
        dryGainDrone.gain.setValueAtTime(0.3, audioContext.currentTime); // Default drone dry level
        console.log('initAudio: dryGainDrone initialized.');

        audioInitialized = true;
        updateAudioStatus('Initialized');
        updateAudioState();
        console.log(`initAudio: AudioContext initialized successfully. State: ${audioContext.state}`);
      } catch (error) {
        audioInitialized = false;
        updateAudioStatus('Failed to initialize');
        console.error('initAudio: Failed to initialize AudioContext or effect nodes:', error);
      }
    }

    ws.onopen = () => {
      document.getElementById('status').textContent = 'Connected';
      ws.send(JSON.stringify({ type: 'register', id }));
    };

    ws.onmessage = (event) => {
      try {
        const data = JSON.parse(event.data);
        if (data.type === 'note') {
          console.log(`SRC: Received note '${data.note}'`);
          updateNoteReceived(data.note);
          playNote(data.note);
        } else if (data.type === 'clients') {
          console.log('SRC: Received client list update.');
        } else if (data.type === 'apply_effect' && data.effect && data.effect.type === 'delay') {
          console.log('SRC: Received delay effect settings:', data.effect);
          currentDelayTime = Math.max(0, Math.min(MAX_DELAY, data.effect.delayTime || 0));
          currentFeedbackAmount = Math.max(0, Math.min(0.95, data.effect.feedback || 0)); // Cap feedback

          if (audioContext && delayNode && feedbackNode) {
            const applyTime = audioContext.currentTime;
            delayNode.delayTime.setValueAtTime(currentDelayTime, applyTime);
            feedbackNode.gain.setValueAtTime(currentFeedbackAmount, applyTime);
            console.log(`SRC: Applied delay - Time: ${currentDelayTime}, Feedback: ${currentFeedbackAmount}`);
            document.getElementById('audioStatus').textContent = `Delay: T=${currentDelayTime.toFixed(2)}s F=${currentFeedbackAmount.toFixed(2)}`;
          } else {
            console.warn('SRC: AudioContext or delay nodes not ready for effect update. Parameters stored.');
          }
        } else if (data.type === 'start_drone') {
          if (audioInitialized) {
            if (data.hz !== undefined) {
              console.log(`SRC: Received start_drone for ${data.hz} Hz with LFO:`, data.lfo);
              startDrone(null, data.hz, data.lfo ? data.lfo.rate : undefined, data.lfo ? data.lfo.depth : undefined, data.lfo ? data.lfo.type : undefined);
            } else if (data.note !== undefined) { // Fallback for old message type, can be removed later
              console.log(`SRC: Received start_drone for note '${data.note}' (fallback) with LFO:`, data.lfo);
              startDrone(data.note, undefined, data.lfo ? data.lfo.rate : undefined, data.lfo ? data.lfo.depth : undefined, data.lfo ? data.lfo.type : undefined);
            } else {
              console.warn('SRC: start_drone message missing hz or note.');
            }
          } else {
            console.warn('SRC: Audio not initialized, cannot start drone.');
            updateAudioStatus('Error: Init audio before drone.');
          }
        } else if (data.type === 'stop_drone') {
          console.log('SRC: Received stop_drone');
          if (audioInitialized) {
            stopDrone();
          } else {
            console.warn('SRC: Audio not initialized, cannot stop drone.');
          }
        } else if (data.type === 'update_lfo_params') {
          console.log('SRC: Received LFO parameter update:', data.params);
          if (data.params) {
            currentLfoRate = data.params.rate !== undefined ? data.params.rate : currentLfoRate;
            currentLfoDepth = data.params.depth !== undefined ? data.params.depth : currentLfoDepth;
            currentLfoType = data.params.type !== undefined ? data.params.type : currentLfoType;
            
            if (droneActive && lfo && lfoGain && audioContext) {
              lfo.frequency.setValueAtTime(currentLfoRate, audioContext.currentTime);
              lfoGain.gain.setValueAtTime(currentLfoDepth, audioContext.currentTime);
              lfo.type = currentLfoType;
              console.log(`SRC: Updated active LFO - Rate: ${currentLfoRate}, Depth: ${currentLfoDepth}, Type: ${currentLfoType}`);
              updateAudioStatus(`Drone LFO: ${currentLfoType} ${currentLfoRate.toFixed(1)}Hz D:${currentLfoDepth.toFixed(2)}`);
            } else {
              console.log('SRC: LFO parameters stored for next drone.');
            }
          }
        } else {
          console.warn('SRC: Received unknown message type:', data);
        }
      } catch (error) {
        console.error('SRC: Error processing message:', event.data, error);
      }
    };

    ws.onclose = () => {
      document.getElementById('status').textContent = 'Disconnected';
    };

    async function playNote(note) {
      if (!audioInitialized || !audioContext || !delayNode || !feedbackNode || !wetGainNode) {
        console.error('playNote: Audio system or delay nodes not initialized properly.');
        // Attempt to initialize if not already, but this might be too late if called rapidly
        if (!audioInitialized) {
            console.log('playNote: Audio not initialized, attempting to initialize...');
            updateAudioStatus('Auto-initializing...');
            await initAudio();
            if (!audioInitialized || !audioContext || !delayNode || !feedbackNode || !wetGainNode) {
                console.error('playNote: Post-initialization check failed. Aborting playback.');
                updateAudioStatus('Initialization / Effect Setup failed');
                return;
            }
        }
        updateAudioStatus('Error: Audio/Effects not ready');
        return;
      }

      // console.log(`playNote: Attempting note '${note}'. Context state: ${audioContext.state}`);
      // updateAudioState(); // This might be too verbose now

      if (audioContext.state === 'suspended') {
        // console.log('playNote: AudioContext suspended, attempting resume...');
        try {
          await audioContext.resume();
          updateAudioStatus('Resumed');
          updateAudioState();
          // console.log(`playNote: AudioContext resumed. New state: ${audioContext.state}`);
        } catch (error) {
          console.error('playNote: Failed to resume AudioContext:', error);
          updateAudioStatus('Resume failed');
          return;
        }
      }
      
      if (audioContext.state !== 'running') {
        console.error(`playNote: AudioContext not running. State: ${audioContext.state}`);
        updateAudioStatus(`Not running: ${audioContext.state}`);
        return;
      }

      try {
        const oscillator = audioContext.createOscillator();
        const mainNoteGain = audioContext.createGain(); // This gain will handle the note's envelope

        oscillator.type = 'sine';
        oscillator.frequency.setValueAtTime(noteToFrequency(note), audioContext.currentTime);

        // Envelope for the main note sound
        mainNoteGain.gain.setValueAtTime(0.8, audioContext.currentTime);
        mainNoteGain.gain.exponentialRampToValueAtTime(0.001, audioContext.currentTime + 1.5);

        // Connect oscillator to its envelope gain
        oscillator.connect(mainNoteGain);

        // console.log(`playNote: About to connect delay. currentDelayTime: ${currentDelayTime}, currentFeedbackAmount: ${currentFeedbackAmount}`);
        // console.log(`playNote: delayNode.delayTime.value: ${delayNode.delayTime.value}, feedbackNode.gain.value: ${feedbackNode.gain.value}`);

        // --- Dry Path --- 
        // Connect main note sound directly to destination if you want a dry signal
        // For a fully effected sound, you might skip this direct connection or add a dry/wet mix control later.
        // Let's make it mostly wet for a pronounced delay effect initially.
        // A small amount of dry can help with attack perception.
        const dryGain = audioContext.createGain();
        dryGain.gain.setValueAtTime(0.3, audioContext.currentTime); // Adjust dry level
        mainNoteGain.connect(dryGain);
        dryGain.connect(audioContext.destination);

        // --- Wet Path (Delay) ---
        mainNoteGain.connect(delayNode);      // Send note to the delay input
        delayNode.connect(wetGainNode);       // Delayed signal to its dedicated gain
        wetGainNode.connect(audioContext.destination); // Wet signal to output

        // Feedback loop for the delay
        delayNode.connect(feedbackNode);
        feedbackNode.connect(delayNode);
        
        oscillator.start(audioContext.currentTime);
        oscillator.stop(audioContext.currentTime + 1.5); // Oscillator stops after its envelope
        
        // Disconnect mainNoteGain from delay path after note envelope finishes to stop feeding delay indefinitely
        // This is important if the mainNoteGain envelope goes to zero.
        setTimeout(() => {
            if (mainNoteGain && delayNode && mainNoteGain.numberOfOutputs > 0) {
                try { 
                    mainNoteGain.disconnect(delayNode);
                    // console.log("Disconnected mainNoteGain from delayNode");
                } catch(e) { console.warn("Error disconnecting mainNoteGain from delayNode:", e); }
            }
             if (dryGain && audioContext.destination && dryGain.numberOfOutputs > 0) {
                try { 
                    dryGain.disconnect(audioContext.destination);
                    // console.log("Disconnected dryGain from destination");
                } catch(e) { console.warn("Error disconnecting dryGain from destination:", e); }
            }
            // It's also good practice to disconnect the oscillator if it hasn't been already
            // by its own .stop() method implicitly disconnecting it.
            if (oscillator && oscillator.numberOfOutputs > 0) {
                 try { oscillator.disconnect(); /* console.log("Disconnected oscillator"); */ } catch(e) { /* might already be disconnected */ }
            }
        }, 1600); 


        updateAudioStatus(`Playing ${note} with Delay`);
        console.log(`playNote: Successfully scheduled '${note}' with delay. Context state: ${audioContext.state}`);
        
      } catch (error) {
        updateAudioStatus('Error playing note with delay');
        console.error('playNote: Error during Web Audio API calls with delay:', error);
      }
    }

    async function startDrone(note, hz, lfoRate = currentLfoRate, lfoDepth = currentLfoDepth, lfoType = currentLfoType) {
      if (!audioInitialized || !audioContext || !delayNode || !feedbackNode || !wetGainNode || !dryGainDrone) {
        console.error('startDrone: Audio system or required nodes not initialized properly.');
        updateAudioStatus('Error: Audio/Effects not ready for drone.');
        return;
      }

      if (droneActive) {
        console.log('startDrone: Drone already active, stopping previous one first.');
        await stopDrone(); // Ensure previous drone is fully stopped and LFO is cleared
      }

      const frequency = hz !== undefined ? hz : (note ? noteToFrequency(note) : noteToFrequency('A3')); // Prioritize Hz, then note, then default
      const displayValue = hz !== undefined ? `${hz.toFixed(2)} Hz` : note;

      console.log(`startDrone: Starting drone for ${displayValue}. LFO - Rate: ${lfoRate}, Depth: ${lfoDepth}, Type: ${lfoType}. Context state: ${audioContext.state}`);
      updateAudioState();

      if (audioContext.state === 'suspended') {
        try {
          await audioContext.resume();
          updateAudioStatus('Resumed for Drone');
          updateAudioState();
        } catch (error) {
          console.error('startDrone: Failed to resume AudioContext:', error);
          updateAudioStatus('Drone Resume failed');
          return;
        }
      }

      try {
        droneOscillator = audioContext.createOscillator();
        droneGainNode = audioContext.createGain();

        droneOscillator.type = 'sine'; 
        droneOscillator.frequency.setValueAtTime(frequency, audioContext.currentTime);
        droneGainNode.gain.setValueAtTime(0.5, audioContext.currentTime); // Base gain for drone

        // --- LFO Setup for Amplitude Modulation (Tremolo) ---
        lfo = audioContext.createOscillator();
        lfo.type = lfoType;
        lfo.frequency.setValueAtTime(lfoRate, audioContext.currentTime);

        lfoGain = audioContext.createGain();
        lfoGain.gain.setValueAtTime(lfoDepth, audioContext.currentTime);

        // Connect LFO path: LFO -> LFO Gain -> Modulates the main drone's gain
        lfo.connect(lfoGain);
        lfoGain.connect(droneGainNode.gain); // Modulate the gain parameter of droneGainNode
        console.log('startDrone: LFO connected to droneGainNode.gain');

        lfo.start(audioContext.currentTime);
        // --- End LFO Setup ---

        droneOscillator.connect(droneGainNode);

        // --- Drone Dry Path ---
        droneGainNode.connect(dryGainDrone);
        dryGainDrone.connect(audioContext.destination);

        // --- Drone Wet Path (Delay) ---
        droneGainNode.connect(delayNode); // Connect to the existing shared delay line
        // delayNode is already connected to wetGainNode -> destination and feedbackNode -> delayNode

        droneOscillator.start(audioContext.currentTime);
        droneActive = true;
        document.getElementById('testTone').style.display = 'none'; // Hide test tone when drone is active
        updateAudioStatus(`Drone: ${displayValue} | LFO: ${lfoType} ${lfoRate.toFixed(1)}Hz D:${lfoDepth.toFixed(2)}`);
        console.log(`startDrone: Drone '${displayValue}' started successfully with LFO.`);

      } catch (error) {
        updateAudioStatus('Error starting drone');
        console.error('startDrone: Error during Web Audio API calls:', error);
        droneActive = false; // Ensure flag is reset on error
      }
    }

    async function stopDrone() {
      if (!droneActive || !droneOscillator || !droneGainNode) {
        // console.log('stopDrone: No active drone to stop.');
        return;
      }
      console.log('stopDrone: Stopping drone...');
      try {
        const stopTime = audioContext.currentTime + 0.1; // Short fade out
        droneGainNode.gain.exponentialRampToValueAtTime(0.0001, stopTime);
        
        droneOscillator.stop(stopTime);

        // Disconnect after stopping
        // Use a short timeout to ensure nodes are disconnected after they've finished processing
        setTimeout(() => {
            if (droneGainNode) {
                try { droneGainNode.disconnect(); } catch(e) { /* ignore */ }
            }
            if (droneOscillator) {
                try { droneOscillator.disconnect(); } catch(e) { /* ignore */ }
            }
            if (lfo) {
                try { lfo.disconnect(); } catch(e) { /* ignore */ }
            }
            if (lfoGain) {
                try { lfoGain.disconnect(); } catch(e) { /* ignore */ }
            }
            // dryGainDrone remains connected to destination, ready for next drone
        }, (stopTime - audioContext.currentTime + 0.1) * 1000); // Timeout slightly after stop time

      } catch (error) {
        console.error('stopDrone: Error during Web Audio API calls:', error);
      }
      droneOscillator = null;
      droneGainNode = null;
      // Clear LFO nodes as well
      if (lfo) { 
        try { if(lfo.playbackState === lfo.PLAYING_STATE || lfo.playbackState === lfo.SCHEDULED_STATE) lfo.stop(audioContext.currentTime); } catch(e) {/* already stopped or not started */}
        lfo = null; 
      }
      if (lfoGain) { lfoGain = null; }

      droneActive = false;
      document.getElementById('testTone').style.display = 'block'; // Re-show test tone
      updateAudioStatus('Drone stopped');
      console.log('stopDrone: Drone stopped and cleaned up.');
    }

    function noteToFrequency(note) {
      const noteFrequencies = {
        // Adding more notes for a C minor arpeggio / A minor context
        'A3': 220.00,  // A below middle C
        'C4': 261.63,  // Middle C
        'D4': 293.66,
        'E4': 329.63,
        'F4': 349.23,
        'G4': 392.00,  // G above middle C
        'A4': 440.00,
        'B4': 493.88,
        'C5': 523.25
        // Add more notes as needed
      };
      if (!noteFrequencies[note]) {
        console.warn(`noteToFrequency: Frequency for note '${note}' not found. Defaulting to A4 (440Hz).`);
        return 440.00; // Default to A4 if note not found
      }
      return noteFrequencies[note];
    }
  </script>
</body>
</html>