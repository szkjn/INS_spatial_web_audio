<!-- public/src.html -->
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>SRC Client</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0"> <!-- For better mobile scaling -->
  <style>
    body {
      background-color: #121212;
      color: #e0e0e0;
      font-family: 'Courier New', Courier, monospace;
      font-size: 1.2em; /* Larger base font size */
      margin: 20px;
      display: flex;
      flex-direction: column;
      align-items: center; /* Center content */
      text-align: center;
    }
    h1 {
      color: #ffffff;
      border-bottom: 1px solid #444;
      padding-bottom: 5px;
      margin-bottom: 20px;
    }
    button {
      background-color: #333;
      color: #e0e0e0;
      border: 1px solid #555;
      padding: 12px 18px; /* Larger padding for buttons */
      margin: 10px 5px; /* More margin for buttons */
      cursor: pointer;
      border-radius: 4px;
      font-size: 1em; /* Relative to body font size */
    }
    button:hover {
      background-color: #444;
    }
    #status {
      font-weight: bold;
      margin-bottom: 15px;
    }
    #noteIndicator {
      background-color: #1f1f1f;
      border: 1px solid #333;
      border-radius: 5px;
      padding: 15px;
      margin-top: 20px;
      width: 80%; /* Adjust width as needed */
      max-width: 400px; /* Max width for larger screens */
    }
    #noteIndicator h3 {
        margin-top: 0;
        color: #ffffff;
    }
    #noteIndicator p {
        margin: 8px 0;
        font-size: 0.9em; /* Slightly smaller than body, but still larger overall */
    }
  </style>
</head>
<body>
  <h1>SRC Client</h1>
  <p id="status">Connecting...</p>
  <button id="startSessionButton" style="display: block;">Start Session</button>
  <button id="testTone" style="display: none;">Test Tone</button>
  <div id="noteIndicator">
    <h3>Last Note Received:</h3>
    <p id="lastNote">None</p>
    <p id="noteCount">Notes received: 0</p>
    <p id="audioStatus">Audio: Not initialized</p>
    <p id="audioState">State: Unknown</p>
    <p id="browserInfo">Browser: Checking...</p>
    <p id="volumeInfo">Volume: Unknown</p>
  </div>

  <script>
    const id = 'src-' + Math.random().toString(36).substr(2, 5);
    const ws = new WebSocket(`ws://${location.host}`);
    let audioContext;
    let audioInitialized = false;
    let noteCount = 0;

    // Delay effect nodes and parameters
    let delayNode = null;
    let feedbackNode = null;
    let wetGainNode = null; // To control overall level of delayed sound
    let currentDelayTime = 0;
    let currentFeedbackAmount = 0;
    const MAX_DELAY = 2.0; // Maximum delay time in seconds

    // Check browser support and capabilities
    function checkBrowserSupport() {
      const isIOS = /iPad|iPhone|iPod/.test(navigator.userAgent);
      const isAndroid = /Android/.test(navigator.userAgent);
      const isChrome = /Chrome/.test(navigator.userAgent);
      const isSafari = /Safari/.test(navigator.userAgent) && !isChrome;
      
      let browserInfo = `${isIOS ? 'iOS' : isAndroid ? 'Android' : 'Desktop'}`;
      if (isChrome) browserInfo += ' Chrome';
      else if (isSafari) browserInfo += ' Safari';
      
      document.getElementById('browserInfo').textContent = `Browser: ${browserInfo}`;
      
      // Check if Web Audio API is supported
      if (!window.AudioContext && !window.webkitAudioContext) {
        document.getElementById('audioStatus').textContent = 'Audio: Not supported';
        return false;
      }
      return true;
    }

    // Show init audio button initially
    document.getElementById('startSessionButton').style.display = 'block';
    document.getElementById('startSessionButton').onclick = startSession; 
    document.getElementById('testTone').onclick = () => playNote('A4');
    
    checkBrowserSupport();

    function updateAudioStatus(status) {
      document.getElementById('audioStatus').textContent = `Audio: ${status}`;
    }

    function updateAudioState() {
      if (audioContext) {
        document.getElementById('audioState').textContent = `State: ${audioContext.state}`;
      }
    }

    function updateNoteReceived(note) {
      noteCount++;
      document.getElementById('lastNote').textContent = note;
      document.getElementById('noteCount').textContent = `Notes received: ${noteCount}`;
      
      // Flash the indicator
      const indicator = document.getElementById('noteIndicator');
      indicator.style.backgroundColor = '#90EE90';
      setTimeout(() => {
        indicator.style.backgroundColor = '';
      }, 500);
    }

    async function startSession() {
        console.log('startSession: Initiating session...');
        await initAudio();

        if (audioInitialized) {
            console.log('startSession: Audio initialized.');
            document.getElementById('startSessionButton').style.display = 'none';
            document.getElementById('testTone').style.display = 'block';
        } else {
            console.error('startSession: Audio initialization failed.');
        }
    }

    async function initAudio() {
      console.log('initAudio: Attempting to initialize AudioContext...');
      try {
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        
        if (audioContext.state === 'suspended') {
          console.log('initAudio: AudioContext is suspended, attempting to resume...');
          await audioContext.resume();
        }
        
        // Initialize Delay Nodes
        delayNode = audioContext.createDelay(MAX_DELAY);
        feedbackNode = audioContext.createGain();
        wetGainNode = audioContext.createGain();

        // Set initial delay parameters (can be overridden by server)
        // These should be the global currentDelayTime and currentFeedbackAmount
        // which might have been set by a message before initAudio if ORC sends effect early.
        delayNode.delayTime.setValueAtTime(currentDelayTime, audioContext.currentTime);
        feedbackNode.gain.setValueAtTime(currentFeedbackAmount, audioContext.currentTime);
        wetGainNode.gain.setValueAtTime(1.0, audioContext.currentTime); // Start with wet signal at full volume

        console.log('initAudio: Delay nodes initialized.');

        audioInitialized = true;
        updateAudioStatus('Initialized');
        updateAudioState();
        console.log(`initAudio: AudioContext initialized successfully. State: ${audioContext.state}`);
      } catch (error) {
        audioInitialized = false;
        updateAudioStatus('Failed to initialize');
        console.error('initAudio: Failed to initialize AudioContext or effect nodes:', error);
      }
    }

    ws.onopen = () => {
      document.getElementById('status').textContent = 'Connected';
      ws.send(JSON.stringify({ type: 'register', id }));
    };

    ws.onmessage = (event) => {
      try {
        const data = JSON.parse(event.data);
        if (data.type === 'note') {
          console.log(`SRC: Received note '${data.note}'`);
          updateNoteReceived(data.note);
          playNote(data.note);
        } else if (data.type === 'clients') {
          console.log('SRC: Received client list update.');
        } else if (data.type === 'apply_effect' && data.effect && data.effect.type === 'delay') {
          console.log('SRC: Received delay effect settings:', data.effect);
          const newDelayTime = Math.max(0, Math.min(MAX_DELAY, data.effect.delayTime || 0));
          const newFeedbackAmount = Math.max(0, Math.min(0.95, data.effect.feedback || 0)); // Cap feedback

          currentDelayTime = newDelayTime;
          currentFeedbackAmount = newFeedbackAmount;

          if (audioContext && delayNode && feedbackNode) {
            const applyTime = audioContext.currentTime;
            delayNode.delayTime.setValueAtTime(currentDelayTime, applyTime);
            feedbackNode.gain.setValueAtTime(currentFeedbackAmount, applyTime);
            console.log(`SRC: Applied delay - Time: ${currentDelayTime}, Feedback: ${currentFeedbackAmount}`);
            document.getElementById('audioStatus').textContent = `Delay: T=${currentDelayTime.toFixed(2)}s F=${currentFeedbackAmount.toFixed(2)}`;
          } else {
            console.warn('SRC: AudioContext or delay nodes not ready for effect update. Parameters stored.');
          }
        } else {
          console.warn('SRC: Received unknown message type:', data);
        }
      } catch (error) {
        console.error('SRC: Error processing message:', event.data, error);
      }
    };

    ws.onclose = () => {
      document.getElementById('status').textContent = 'Disconnected';
    };

    async function playNote(note) {
      if (!audioInitialized || !audioContext || !delayNode || !feedbackNode || !wetGainNode) {
        console.error('playNote: Audio system or delay nodes not initialized properly.');
        // Attempt to initialize if not already, but this might be too late if called rapidly
        if (!audioInitialized) {
            console.log('playNote: Audio not initialized, attempting to initialize...');
            updateAudioStatus('Auto-initializing...');
            await initAudio();
            if (!audioInitialized || !audioContext || !delayNode || !feedbackNode || !wetGainNode) {
                console.error('playNote: Post-initialization check failed. Aborting playback.');
                updateAudioStatus('Initialization / Effect Setup failed');
                return;
            }
        }
        updateAudioStatus('Error: Audio/Effects not ready');
        return;
      }

      // console.log(`playNote: Attempting note '${note}'. Context state: ${audioContext.state}`);
      // updateAudioState(); // This might be too verbose now

      if (audioContext.state === 'suspended') {
        // console.log('playNote: AudioContext suspended, attempting resume...');
        try {
          await audioContext.resume();
          updateAudioStatus('Resumed');
          updateAudioState();
          // console.log(`playNote: AudioContext resumed. New state: ${audioContext.state}`);
        } catch (error) {
          console.error('playNote: Failed to resume AudioContext:', error);
          updateAudioStatus('Resume failed');
          return;
        }
      }
      
      if (audioContext.state !== 'running') {
        console.error(`playNote: AudioContext not running. State: ${audioContext.state}`);
        updateAudioStatus(`Not running: ${audioContext.state}`);
        return;
      }

      try {
        const oscillator = audioContext.createOscillator();
        const mainNoteGain = audioContext.createGain(); // This gain will handle the note's envelope

        oscillator.type = 'sine';
        oscillator.frequency.setValueAtTime(noteToFrequency(note), audioContext.currentTime);

        // Envelope for the main note sound
        mainNoteGain.gain.setValueAtTime(0.8, audioContext.currentTime);
        mainNoteGain.gain.exponentialRampToValueAtTime(0.001, audioContext.currentTime + 1.5);

        // Connect oscillator to its envelope gain
        oscillator.connect(mainNoteGain);

        // console.log(`playNote: About to connect delay. currentDelayTime: ${currentDelayTime}, currentFeedbackAmount: ${currentFeedbackAmount}`);
        // console.log(`playNote: delayNode.delayTime.value: ${delayNode.delayTime.value}, feedbackNode.gain.value: ${feedbackNode.gain.value}`);

        // --- Dry Path --- 
        // Connect main note sound directly to destination if you want a dry signal
        // For a fully effected sound, you might skip this direct connection or add a dry/wet mix control later.
        // Let's make it mostly wet for a pronounced delay effect initially.
        // A small amount of dry can help with attack perception.
        const dryGain = audioContext.createGain();
        dryGain.gain.setValueAtTime(0.3, audioContext.currentTime); // Adjust dry level
        mainNoteGain.connect(dryGain);
        dryGain.connect(audioContext.destination);

        // --- Wet Path (Delay) ---
        mainNoteGain.connect(delayNode);      // Send note to the delay input
        delayNode.connect(wetGainNode);       // Delayed signal to its dedicated gain
        wetGainNode.connect(audioContext.destination); // Wet signal to output

        // Feedback loop for the delay
        delayNode.connect(feedbackNode);
        feedbackNode.connect(delayNode);
        
        oscillator.start(audioContext.currentTime);
        oscillator.stop(audioContext.currentTime + 1.5); // Oscillator stops after its envelope
        
        // Disconnect mainNoteGain from delay path after note envelope finishes to stop feeding delay indefinitely
        // This is important if the mainNoteGain envelope goes to zero.
        setTimeout(() => {
            if (mainNoteGain && delayNode && mainNoteGain.numberOfOutputs > 0) {
                try { 
                    mainNoteGain.disconnect(delayNode);
                    // console.log("Disconnected mainNoteGain from delayNode");
                } catch(e) { console.warn("Error disconnecting mainNoteGain from delayNode:", e); }
            }
             if (dryGain && audioContext.destination && dryGain.numberOfOutputs > 0) {
                try { 
                    dryGain.disconnect(audioContext.destination);
                    // console.log("Disconnected dryGain from destination");
                } catch(e) { console.warn("Error disconnecting dryGain from destination:", e); }
            }
            // It's also good practice to disconnect the oscillator if it hasn't been already
            // by its own .stop() method implicitly disconnecting it.
            if (oscillator && oscillator.numberOfOutputs > 0) {
                 try { oscillator.disconnect(); /* console.log("Disconnected oscillator"); */ } catch(e) { /* might already be disconnected */ }
            }
        }, 1600); 


        updateAudioStatus(`Playing ${note} with Delay`);
        console.log(`playNote: Successfully scheduled '${note}' with delay. Context state: ${audioContext.state}`);
        
      } catch (error) {
        updateAudioStatus('Error playing note with delay');
        console.error('playNote: Error during Web Audio API calls with delay:', error);
      }
    }

    function noteToFrequency(note) {
      const noteFrequencies = {
        // Adding more notes for a C minor arpeggio / A minor context
        'A3': 220.00,  // A below middle C
        'C4': 261.63,  // Middle C
        'D4': 293.66,
        'E4': 329.63,
        'F4': 349.23,
        'G4': 392.00,  // G above middle C
        'A4': 440.00,
        'B4': 493.88,
        'C5': 523.25
        // Add more notes as needed
      };
      if (!noteFrequencies[note]) {
        console.warn(`noteToFrequency: Frequency for note '${note}' not found. Defaulting to A4 (440Hz).`);
        return 440.00; // Default to A4 if note not found
      }
      return noteFrequencies[note];
    }
  </script>
</body>
</html>